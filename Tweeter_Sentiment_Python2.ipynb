{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 4000 instances, test on 500 instances\n",
      "Most Informative Features\n",
      "          contains(miss) = True           negati : positi =     20.3 : 1.0\n",
      "           contains(sad) = True           negati : positi =     19.0 : 1.0\n",
      "       contains(believe) = True           negati : positi =     16.6 : 1.0\n",
      "        contains(thanks) = True           positi : negati =     16.4 : 1.0\n",
      "     contains(community) = True           positi : negati =     15.7 : 1.0\n",
      "          contains(sick) = True           negati : positi =     13.7 : 1.0\n",
      "         contains(enjoy) = True           positi : negati =     13.7 : 1.0\n",
      "          contains(cool) = True           positi : negati =     11.7 : 1.0\n",
      "          contains(poor) = True           negati : positi =     11.7 : 1.0\n",
      "         contains(thank) = True           positi : negati =     11.5 : 1.0\n",
      "None\n",
      "This classifier is currently running at (percentage): 0.784\n",
      "\n",
      "Tweet Sentiment Analyzer\n",
      "\tBy Patrick Gaston\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Enter your tweet here: good morning. everything looks great\n",
      "('The input is considered: ', 'positive')\n",
      "\n",
      "\n",
      "Try another tweet: hello world\n",
      "('The input is considered: ', 'positive')\n",
      "\n",
      "\n",
      "You know what... Try another tweet: hey \n",
      "('The input is considered: ', 'positive')\n",
      "\n",
      "\n",
      "Would you like to enter 3 more tweets? Enter (Y/N) damn it\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "# sentiment.py\n",
    "# by: Patrick Gaston\n",
    "# Twitter Sentiment Analysis\n",
    "# Computational Linguistics Final Project SPRING 2016\n",
    "\n",
    "''' Automatic sentiment (positive or negative) extractor from an input '''\n",
    "\n",
    "# import libs and packages\n",
    "import nltk\n",
    "import re\n",
    "import nltk.classify.util\n",
    "from nltk.corpus import *\n",
    "from nltk.corpus import TwitterCorpusReader\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "\n",
    "## --------------------------------PREPROCESS TRAINING DATA----------------------------------------- ##\n",
    "\n",
    "'''  \n",
    "\tPREPROCESS Tweets    \n",
    "\t\tsteps:\n",
    "\t\t\t1. change '@xxx' to '@user' (@EaglesFan4Life == '@user')\n",
    "\t\t\t2. lowercase all characters ('Thanks' == 'thanks')\n",
    "\t\t\t3. remove hashtags ('#love' == 'love')\n",
    "\t\t\t4. remove multiple white spaces ('       ' == ' ')\n",
    "\t\t\t5. remove punctuation ('Hey!!!!!' == 'Hey')\n",
    "\t\t\t6. remove URLs ('https:twit.co...' == 'URL')\n",
    "\t\t\t7. if more than 3 consonants in sequence, reduce to 2 ('yeaaaaaaaah' == 'yeaah')\n",
    "\t\t\t\t\n",
    "\t'''\n",
    "\n",
    "def process_tweet(tweets):\n",
    "\tnewtweets = []\n",
    "\tfor items in tweets:\n",
    "\t\tnewitem = []\n",
    "\t\tfor item in items:\n",
    "\t\t\tif len(item) >= 3:\n",
    "\t\t\t\titem = re.sub(r'(.)\\1+', r'\\1\\1', item)\n",
    "\t\t\t\titem = item.lower()\n",
    "\t\t\t\tif '@' in item:\n",
    "\t\t\t\t\titem = '@user'\n",
    "\t\t\t\telif '#' in item:\n",
    "\t\t\t\t\titem = item[1:]\n",
    "\t\t\t\telif item == 'luv':\n",
    "\t\t\t\t\titem = 'love'\n",
    "\t\t\t\telif 'http' in item:\n",
    "\t\t\t\t\titem = 'UR'\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\n",
    "\t\t\t\tnewitem.append(item)\n",
    "\t\tnewtweets.append(newitem)\n",
    "\treturn newtweets\n",
    "\n",
    "\t\n",
    "''' create tuples in list of tweets and add sentiment \"positive\" or \"negative\" to tweets \n",
    "\n",
    "(['@user', 'hey', '!', ':)', 'long', 'time', 'no', 'talk',], 'positive')\n",
    "(['@user', 'as', 'matt', 'would', 'say', '.', 'welcome', 'to', 'adulthood', '..', ':)', 'URL'], 'positive')\n",
    "\n",
    "'''\t\n",
    "\n",
    "def get_words(tweets):\n",
    "\twholelist = []\n",
    "\tfor (words, sentence) in tweets:\n",
    "\t\twholelist.extend(words)\n",
    "\treturn wholelist\n",
    "\n",
    "def get_word_feats(wordlist):\n",
    "\twordlist = nltk.FreqDist(wordlist)\n",
    "\tword_feats = wordlist.keys()\n",
    "\treturn word_feats\n",
    "\t\n",
    "''' FEATURE EXTRACTIOIN!\n",
    "\n",
    "extract features from data sets to implement in machine learning algorithm (Classifier: Naive Bayes)\n",
    "\n",
    "'''\n",
    "\n",
    "def extract_feats(doc):\n",
    "\tdoc_words = set(doc)\n",
    "\tfeatures = {}\n",
    "\tfor word in doc:\n",
    "\t\tfeatures['contains(%s)' % word] = (word in doc_words)\n",
    "\treturn features\n",
    "\n",
    "\n",
    "def add_pos_sentiment(tweets):\n",
    "\tnewlist = []\n",
    "\tfor items in tweets:\n",
    "\t\tsentence, sentiment = items, \"positive\"\n",
    "\t\tnewlist.append((sentence, sentiment))\n",
    "\treturn newlist\n",
    "\n",
    "def add_neg_sentiment(tweets):\n",
    "\tnewlist = []\n",
    "\tfor items in tweets:\n",
    "\t\tsentence, sentiment = items, \"negative\"\n",
    "\t\tnewlist.append((sentence, sentiment))\n",
    "\treturn newlist\n",
    "\n",
    "\n",
    "'''  \n",
    "\tPREPROCESS Instagram Posts  #TODO    \n",
    "\t\tsteps:\n",
    "\t\t\t1. change '@xxx' to '@user' (@EaglesFan4Life == '@user')\n",
    "\t\t\t2. lowercase all characters ('Thanks' == 'thanks')\n",
    "\t\t\t3. remove hashtags ('#love' == 'love')\n",
    "\t\t\t4. remove multiple white spaces ('       ' == ' ')\n",
    "\t\t\t5. remove punctuation ('Hey!!!!!' == 'Hey')\n",
    "\t\t\t6. remove URLs ('https:twit.co...' == 'URL')\n",
    "\t\t\t7. if more than 3 consonants in sequence, reduce to 2 ('yeaaaaaaaah' == 'yeaah')\n",
    "\t\t\t\t\n",
    "\t'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## --------------------------------CLASSIFIER + EXECUTION---------------------------------------- ##\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\t''' IMPORT DOWNLOADED TWEETS\n",
    "\tsteps:\n",
    "\t\t\t1. download twitter_samples NLTK corpus for training data\n",
    "\t\t\t2. indicate path in directory and assign to variable\n",
    "\t\t\t3. Read file to/with TwitterCorpusReader to access methods (Here I need .tokenized())  \n",
    "\t'''\n",
    "\t\n",
    "\t# assign variable to path of training data\t\t\t\n",
    "\tposroot = '/Users/Eva/nltk_data/corpora/twitter_samples/positive_tweets.json'\n",
    "\tnegroot = '/Users/Eva/nltk_data/corpora/twitter_samples/negative_tweets.json'\n",
    "\n",
    "\tpos_reader = TwitterCorpusReader(posroot, '.*\\.json')\n",
    "\tneg_reader = TwitterCorpusReader(negroot, '.*\\.json')\n",
    "\n",
    "\traw_pos_tweets = pos_reader.tokenized(\".\")\n",
    "\traw_neg_tweets = neg_reader.tokenized(\".\")\n",
    "\t\n",
    "\t\n",
    "\tpos_tweets = process_tweet(raw_pos_tweets)\n",
    "\tneg_tweets = process_tweet(raw_neg_tweets)\n",
    "\n",
    "\tpos_tweets = add_pos_sentiment(pos_tweets)\n",
    "\tneg_tweets = add_neg_sentiment(neg_tweets)\n",
    "\n",
    "\ttweets = pos_tweets[:2000] + neg_tweets[:2000] # [:3750] original\n",
    "\ttesters = pos_tweets[2000:2250] + neg_tweets[2000:2250] # [3750:] original\n",
    "\n",
    "\tword_feats = get_word_feats(get_words(tweets))\n",
    "\n",
    "\ttraining_set = nltk.classify.apply_features(extract_feats, tweets)\n",
    "\ttesting_set = nltk.classify.apply_features(extract_feats, testers)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tclassifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\tprint('train on %d instances, test on %d instances' % (len(tweets), len(testers)))\n",
    "\tprint classifier.show_most_informative_features()\n",
    "\tprint \"This classifier is currently running at (percentage):\", nltk.classify.accuracy(classifier, testing_set)\n",
    "\n",
    "\n",
    "\tprint \"\\nTweet Sentiment Analyzer\"\n",
    "    \n",
    "    #you can test 3 tweets\n",
    "\tpromptuser = raw_input(\"Enter your tweet here: \")\n",
    "\tprint (\"The input is considered: \", classifier.classify(extract_feats(promptuser.split())))\n",
    "\tprompt_again = raw_input(\"\\n\\nTry another tweet: \")\n",
    "\tprint (\"The input is considered: \", classifier.classify(extract_feats(prompt_again.split())))\n",
    "\tprompt_last = raw_input(\"\\n\\nYou know what... Try another tweet: \")\n",
    "\tprint (\"The input is considered: \", classifier.classify(extract_feats(prompt_last.split())))\n",
    "\n",
    "\trun_again = raw_input(\"\\n\\nWould you like to enter 3 more tweets? Enter (Y/N) \")\n",
    "\tif run_again == \"Y\":\n",
    "\t\treturn main()\n",
    "\telse:\n",
    "\t\tprint \"Bye!\"\n",
    "        \n",
    "    \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
